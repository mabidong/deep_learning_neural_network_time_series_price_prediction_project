{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step, import libraries.\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset and encode the date\n",
    "df = pd.read_csv('bitstampUSD_1-min_data_2012-01-01_to_2017-10-20.csv')\n",
    "df['date'] = pd.to_datetime(df['Timestamp'],unit='s').dt.date\n",
    "group = df.groupby('date')\n",
    "Real_Price = group['Weighted_Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "prediction_days = 30\n",
    "df_train= Real_Price[:len(Real_Price)-prediction_days]\n",
    "df_test= Real_Price[len(Real_Price)-prediction_days:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocess\n",
    "training_set = df_train.values\n",
    "training_set = np.reshape(training_set, (len(training_set), 1))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "training_set = sc.fit_transform(training_set)\n",
    "X_train = training_set[0:len(training_set)-1]\n",
    "y_train = training_set[1:len(training_set)]\n",
    "X_train = np.reshape(X_train, (len(X_train), 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 0.0226\n",
      "Epoch 2/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 0.0193\n",
      "Epoch 3/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 0.0160\n",
      "Epoch 4/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 0.0127\n",
      "Epoch 5/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 0.0093\n",
      "Epoch 6/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 0.0062\n",
      "Epoch 7/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 0.0037\n",
      "Epoch 8/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 0.0019\n",
      "Epoch 9/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 7.9336e-04\n",
      "Epoch 10/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 2.9722e-04\n",
      "Epoch 11/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 1.2570e-04\n",
      "Epoch 12/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 8.6341e-05\n",
      "Epoch 13/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.8352e-05\n",
      "Epoch 14/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.7058e-05\n",
      "Epoch 15/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.6689e-05\n",
      "Epoch 16/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.4990e-05\n",
      "Epoch 17/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.4178e-05\n",
      "Epoch 18/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.2242e-05\n",
      "Epoch 19/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.1770e-05\n",
      "Epoch 20/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.0704e-05\n",
      "Epoch 21/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.9802e-05\n",
      "Epoch 22/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.0145e-05\n",
      "Epoch 23/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 7.0660e-05\n",
      "Epoch 24/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.6510e-05\n",
      "Epoch 25/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.7551e-05\n",
      "Epoch 26/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.8535e-05\n",
      "Epoch 27/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.9259e-05\n",
      "Epoch 28/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.6604e-05\n",
      "Epoch 29/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.6539e-05\n",
      "Epoch 30/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.5869e-05\n",
      "Epoch 31/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.5629e-05\n",
      "Epoch 32/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4286e-05\n",
      "Epoch 33/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.2532e-05\n",
      "Epoch 34/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.3761e-05\n",
      "Epoch 35/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.7144e-05\n",
      "Epoch 36/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.5468e-05\n",
      "Epoch 37/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4248e-05\n",
      "Epoch 38/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4937e-05\n",
      "Epoch 39/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4117e-05\n",
      "Epoch 40/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4823e-05\n",
      "Epoch 41/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.2847e-05\n",
      "Epoch 42/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.8773e-05\n",
      "Epoch 43/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.2999e-05\n",
      "Epoch 44/100\n",
      "2087/2087 [==============================] - 5s 3ms/step - loss: 6.1712e-05A: 0s - loss: 6.1498e-0\n",
      "Epoch 45/100\n",
      "2087/2087 [==============================] - 5s 2ms/step - loss: 6.6401e-05\n",
      "Epoch 46/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.3059e-05\n",
      "Epoch 47/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.3749e-05A: 0s \n",
      "Epoch 48/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.3547e-05\n",
      "Epoch 49/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.2062e-05\n",
      "Epoch 50/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.5233e-05\n",
      "Epoch 51/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.3224e-05\n",
      "Epoch 52/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.4032e-05\n",
      "Epoch 53/100\n",
      "2087/2087 [==============================] - 5s 2ms/step - loss: 6.2054e-05\n",
      "Epoch 54/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.4793e-05\n",
      "Epoch 55/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.4506e-05\n",
      "Epoch 56/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.3512e-05\n",
      "Epoch 57/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.1048e-05\n",
      "Epoch 58/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.3269e-05\n",
      "Epoch 59/100\n",
      "2087/2087 [==============================] - 5s 2ms/step - loss: 6.2989e-05\n",
      "Epoch 60/100\n",
      "2087/2087 [==============================] - 5s 2ms/step - loss: 6.4017e-05\n",
      "Epoch 61/100\n",
      "2087/2087 [==============================] - 6s 3ms/step - loss: 6.4562e-05\n",
      "Epoch 62/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.3200e-05\n",
      "Epoch 63/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.4000e-05\n",
      "Epoch 64/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.3080e-05\n",
      "Epoch 65/100\n",
      "2087/2087 [==============================] - 5s 2ms/step - loss: 6.1924e-05\n",
      "Epoch 66/100\n",
      "2087/2087 [==============================] - 5s 2ms/step - loss: 6.4195e-05\n",
      "Epoch 67/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.4004e-05\n",
      "Epoch 68/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.3382e-05\n",
      "Epoch 69/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.4908e-05\n",
      "Epoch 70/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.3637e-05\n",
      "Epoch 71/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.2739e-05\n",
      "Epoch 72/100\n",
      "2087/2087 [==============================] - 5s 2ms/step - loss: 6.3580e-05\n",
      "Epoch 73/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.2200e-05\n",
      "Epoch 74/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.2368e-05\n",
      "Epoch 75/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4760e-05\n",
      "Epoch 76/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.1845e-05\n",
      "Epoch 77/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.2864e-05\n",
      "Epoch 78/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.1863e-05\n",
      "Epoch 79/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.4626e-05\n",
      "Epoch 80/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.2456e-05\n",
      "Epoch 81/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.1116e-05\n",
      "Epoch 82/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.1800e-05\n",
      "Epoch 83/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.4334e-05\n",
      "Epoch 84/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.4544e-05\n",
      "Epoch 85/100\n",
      "2087/2087 [==============================] - 4s 2ms/step - loss: 6.2163e-05\n",
      "Epoch 86/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.3329e-05\n",
      "Epoch 87/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.5166e-05\n",
      "Epoch 88/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.1878e-05\n",
      "Epoch 89/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.0952e-05\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4095e-05\n",
      "Epoch 91/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4183e-05\n",
      "Epoch 92/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.2069e-05\n",
      "Epoch 93/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.2436e-05\n",
      "Epoch 94/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.1232e-05\n",
      "Epoch 95/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.1577e-05\n",
      "Epoch 96/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.1421e-05\n",
      "Epoch 97/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4800e-05\n",
      "Epoch 98/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.4013e-05\n",
      "Epoch 99/100\n",
      "2087/2087 [==============================] - 3s 1ms/step - loss: 6.0903e-05\n",
      "Epoch 100/100\n",
      "2087/2087 [==============================] - 3s 2ms/step - loss: 6.2262e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b91ff8efd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 4, activation = 'sigmoid', input_shape = (None, 1)))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, batch_size = 5, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions\n",
    "test_set = df_test.values\n",
    "inputs = np.reshape(test_set, (len(test_set), 1))\n",
    "inputs = sc.transform(inputs)\n",
    "inputs = np.reshape(inputs, (len(inputs), 1, 1))\n",
    "predicted_BTC_price = regressor.predict(inputs)\n",
    "predicted_BTC_price = sc.inverse_transform(predicted_BTC_price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
